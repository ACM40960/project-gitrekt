{
  "name": "My workflow",
  "nodes": [
    {
      "parameters": {},
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [
        -384,
        -32
      ],
      "id": "1524d8ac-3e25-4bdf-97ff-e4f531c8f21b",
      "name": "When clicking ‚ÄòExecute workflow‚Äô"
    },
    {
      "parameters": {
        "fileSelector": "/files/test.sql",
        "options": {}
      },
      "type": "n8n-nodes-base.readWriteFile",
      "typeVersion": 1,
      "position": [
        -176,
        -32
      ],
      "id": "ffe478cf-dbde-4708-beb9-eda997d4ab9a",
      "name": "Read/Write Files from Disk"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "you will receive a sql file called text.sql and need to find the mistake on the sql query",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.1,
      "position": [
        320,
        -48
      ],
      "id": "2c9c006e-dde3-4a02-b2d7-d612aacec823",
      "name": "AI Agent"
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "language": "python",
        "pythonCode": "# This code goes inside an n8n \"Code\" node set to Python mode.\n\nimport re\nimport json\nfrom langchain.tools import BaseTool\n\n# --- Tool Definitions ---\n\nclass SQLLogicCheckTool(BaseTool):\n    name = \"SQLLogicCheckTool\"\n    description = \"Useful for analyzing a SQL query string to find logical errors, performance issues, or anti-patterns. Input should be a single string containing the SQL query.\"\n\n    def _run(self, sql_query: str) -> str:\n        \"\"\"Checks for common SQL anti-patterns.\"\"\"\n        findings = []\n        # Check for 'SELECT *'\n        if re.search(r'\\bSELECT\\s+\\*\\s+FROM\\b', sql_query, re.IGNORECASE):\n            findings.append(\"Improvement: Avoid using 'SELECT *'. Explicitly list the columns you need.\")\n        \n        # Check for DELETE/UPDATE without WHERE\n        if re.search(r'\\b(DELETE\\s+FROM|UPDATE\\s+\\w+)\\b', sql_query, re.IGNORECASE) and not re.search(r'\\bWHERE\\b', sql_query, re.IGNORECASE):\n            findings.append(\"CRITICAL: The query contains a DELETE or UPDATE statement without a WHERE clause, which can lead to unintended data loss.\")\n\n        # Check for functions in WHERE clause (non-SARGable)\n        if re.search(r'\\bWHERE\\s+\\w+\\s*\\(', sql_query, re.IGNORECASE):\n            findings.append(\"Performance: Using functions on columns in a WHERE clause can prevent the use of indexes. Consider alternatives.\")\n\n        if not findings:\n            return \"No common logical issues found in the SQL query.\"\n        \n        return \"\\n\".join(findings)\n\nclass StaleTableChecker(BaseTool):\n    name = \"StaleTableChecker\"\n    description = \"Useful for checking if a database table has been updated recently. Input should be the name of the table to check.\"\n\n    def _run(self, table_name: str) -> str:\n        \"\"\"Placeholder for checking table freshness.\"\"\"\n        # In a real scenario, you would connect to your SQLite DB here.\n        # For example:\n        # import sqlite3\n        # con = sqlite3.connect('/path/to/your/database.db')\n        # cur = con.cursor()\n        # # Logic to query table metadata for last update time...\n        # con.close()\n        \n        # For this example, we'll return a mock response.\n        if table_name == \"stale_example_table\":\n            return f\"Warning: The table '{table_name}' has not been updated in over 30 days.\"\n        return f\"Info: The table '{table_name}' is up-to-date.\"\n\nclass ColumnNameAuditTool(BaseTool):\n    name = \"ColumnNameAuditTool\"\n    description = \"Useful for auditing a list of column names to ensure they comply with a specific naming convention (e.g., snake_case). Input should be a list of column name strings.\"\n\n    def _run(self, column_names: list[str]) -> str:\n        \"\"\"Checks if column names are in snake_case.\"\"\"\n        non_compliant_columns = []\n        snake_case_pattern = re.compile(r'^[a-z0-9_]+$')\n        \n        for name in column_names:\n            if not snake_case_pattern.match(name):\n                non_compliant_columns.append(name)\n        \n        if not non_compliant_columns:\n            return \"All column names comply with the snake_case convention.\"\n        \n        return f\"Naming Convention Violation: The following columns are not in snake_case: {', '.join(non_compliant_columns)}\"\n\nclass SchemaDriftTool(BaseTool):\n    name = \"SchemaDriftTool\"\n    description = \"Useful for comparing a desired schema (from a YAML file) with the actual schema from a database to detect drift. Input should be a dictionary with two keys: 'desired' and 'actual', each containing schema information.\"\n\n    def _run(self, schemas: dict) -> str:\n        \"\"\"Compares two schema definitions for differences.\"\"\"\n        desired_schema = schemas.get('desired', {})\n        actual_schema = schemas.get('actual', {})\n        drift_findings = []\n\n        desired_cols = set(desired_schema.keys())\n        actual_cols = set(actual_schema.keys())\n\n        missing_cols = desired_cols - actual_cols\n        extra_cols = actual_cols - desired_cols\n\n        if missing_cols:\n            drift_findings.append(f\"Missing columns in database: {', '.join(missing_cols)}\")\n        if extra_cols:\n            drift_findings.append(f\"Extra columns found in database: {', '.join(extra_cols)}\")\n\n        # Check for type mismatches\n        for col in desired_cols.intersection(actual_cols):\n            if desired_schema[col]['type'] != actual_schema[col]['type']:\n                drift_findings.append(f\"Type mismatch for column '{col}': Expected {desired_schema[col]['type']}, found {actual_schema[col]['type']}.\")\n\n        if not drift_findings:\n            return \"No schema drift detected.\"\n        \n        return \"\\n\".join(drift_findings)\n\nclass ReportWriterTool(BaseTool):\n    name = \"ReportWriterTool\"\n    description = \"The final tool to use. It takes a JSON string containing the findings from all other tools and formats them into a single, clean markdown report. The agent should call this tool last.\"\n\n    def _run(self, analysis_json_string: str) -> str:\n        \"\"\"Formats analysis results into a final report.\"\"\"\n        try:\n            analysis_results = json.loads(analysis_json_string)\n        except json.JSONDecodeError:\n            return \"Error: Invalid JSON format provided to ReportWriterTool.\"\n\n        report = \"# üìã SQL and Schema Analysis Report\\n\\n\"\n        \n        report += \"## üìù Summary of Findings\\n\"\n        \n        if analysis_results.get(\"sql_logic_check\"):\n            report += f\"### SQL Logic Check\\n- {analysis_results['sql_logic_check'].replace(chr(10), chr(10) + '- ')}\\n\\n\"\n        \n        if analysis_results.get(\"stale_table_check\"):\n            report += f\"### Stale Table Check\\n- {analysis_results['stale_table_check']}\\n\\n\"\n            \n        if analysis_results.get(\"column_name_audit\"):\n            report += f\"### Column Name Audit\\n- {analysis_results['column_name_audit']}\\n\\n\"\n            \n        if analysis_results.get(\"schema_drift\"):\n            report += f\"### Schema Drift\\n- {analysis_results['schema_drift'].replace(chr(10), chr(10) + '- ')}\\n\\n\"\n\n        report += \"---\\n*Report generated successfully.*\"\n        return report\n\n# --- Main execution ---\n# This is the function n8n will run.\n\ndef main():\n    # Instantiate all the tools\n    tools = [\n        SQLLogicCheckTool(),\n        StaleTableChecker(),\n        ColumnNameAuditTool(),\n        SchemaDriftTool(),\n        ReportWriterTool()\n    ]\n    return tools\n\n# n8n expects the return value of the last executed line.\n# So we call our main function here.\nreturn main()\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        80,
        -32
      ],
      "id": "3ffa9782-e84b-40f0-bc09-a4c563310d85",
      "name": "Code"
    }
  ],
  "pinData": {},
  "connections": {
    "When clicking ‚ÄòExecute workflow‚Äô": {
      "main": [
        [
          {
            "node": "Read/Write Files from Disk",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Read/Write Files from Disk": {
      "main": [
        [
          {
            "node": "Code",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "2ca13946-05c6-4cd9-b8b5-75d7339d17ca",
  "meta": {
    "instanceId": "ef97483b4b75a2de989abb2eb30b166c581613696accc3203df4d4aa227764bf"
  },
  "id": "GW0vbRgDSVzXyrju",
  "tags": []
}